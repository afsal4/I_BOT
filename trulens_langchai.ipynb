{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦑 Tru initialized with db url sqlite:///default.sqlite .\n",
      "🛑 Secret keys may be written to the database. See the `database_redact_keys` option of Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "# Imports main tools:\n",
    "from trulens_eval import TruChain, Feedback, Tru\n",
    "tru = Tru()\n",
    "tru.reset_database()\n",
    "\n",
    "# Imports from langchain to build app\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishnuprakash/anaconda3/envs/vivi/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=OpenAIEmbeddings()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishnuprakash/anaconda3/envs/vivi/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test a request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task Decomposition is a technique used to break down complex tasks into smaller and simpler steps. This approach allows agents to tackle difficult tasks more effectively by dividing them into manageable components. Task decomposition can be achieved through various methods such as prompting with specific instructions or utilizing human inputs.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What is Task Decomposition?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise feedback functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In groundedness_measure_with_cot_reasons, input source will be set to __record__.app.first.steps.context.first.get_relevant_documents.rets.collect() .\n",
      "✅ In groundedness_measure_with_cot_reasons, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In qs_relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In qs_relevance, input statement will be set to __record__.app.first.steps.context.first.get_relevant_documents.rets .\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval.feedback.provider import OpenAI\n",
    "import numpy as np\n",
    "\n",
    "# Initialize provider class\n",
    "openai = OpenAI()\n",
    "\n",
    "# select context to be used in feedback. the location of context is app specific.\n",
    "from trulens_eval.app import App\n",
    "context = App.select_context(rag_chain)\n",
    "\n",
    "from trulens_eval.feedback import Groundedness\n",
    "grounded = Groundedness(groundedness_provider=OpenAI())\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(grounded.groundedness_measure_with_cot_reasons)\n",
    "    .on(context.collect()) # collect context chunks into a list\n",
    "    .on_output()\n",
    "    .aggregate(grounded.grounded_statements_aggregator)\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_qa_relevance = Feedback(openai.relevance).on_input_output()\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(openai.qs_relevance)\n",
    "    .on_input()\n",
    "    .on(context)\n",
    "    .aggregate(np.mean)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrument the chain for trulens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_recorder = TruChain(rag_chain,\n",
    "    app_id='Chain1_ChatApplication',\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task Decomposition is a technique used to break down complex tasks into smaller and simpler steps. This approach helps agents to plan and execute tasks more efficiently by dividing them into manageable subgoals. Task decomposition can be achieved through various methods, such as using prompting techniques, task-specific instructions, or human inputs.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tru_recorder as recording:\n",
    "    llm_response = rag_chain.invoke(\"What is Task Decomposition?\")\n",
    "\n",
    "display(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve records and feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Record(record_id='record_hash_e38dfcf6d1e68b07b77f0328c09257f7', app_id='Chain1_ChatApplication', cost=Cost(n_requests=2, n_successful_requests=2, n_classes=0, n_tokens=650, n_stream_chunks=0, n_prompt_tokens=590, n_completion_tokens=60, cost=0.000996), perf=Perf(start_time=datetime.datetime(2024, 2, 23, 9, 32, 13, 127592), end_time=datetime.datetime(2024, 2, 23, 9, 32, 17, 600175)), ts=datetime.datetime(2024, 2, 23, 9, 32, 17, 600285), tags='-', meta=None, main_input='What is Task Decomposition?', main_output='Task Decomposition is a technique used to break down complex tasks into smaller and simpler steps. This approach helps agents to plan and execute tasks more efficiently by dividing them into manageable subgoals. Task decomposition can be achieved through various methods, such as using prompting techniques, task-specific instructions, or human inputs.', main_error=None, calls=[RecordAppCall(stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=139650007898208, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableParallel, id=139649997860336, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps.question, method=Method(obj=Obj(cls=langchain_core.runnables.passthrough.RunnablePassthrough, id=139650007899488, init_bindings=None), name='invoke'))], args={'input': 'What is Task Decomposition?', 'config': {'tags': [], 'metadata': {}, 'callbacks': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManager', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 139649925388752, 'init_bindings': None}}, 'recursion_limit': 25, 'configurable': {}}}, rets='What is Task Decomposition?', error=None, perf=Perf(start_time=datetime.datetime(2024, 2, 23, 9, 32, 13, 303997), end_time=datetime.datetime(2024, 2, 23, 9, 32, 13, 365369)), pid=60822, tid=61905), RecordAppCall(stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=139650007898208, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableParallel, id=139649997860336, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps.context, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=139650007898208, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps.context.first, method=Method(obj=Obj(cls=langchain_core.vectorstores.VectorStoreRetriever, id=139649925979968, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps.context.first, method=Method(obj=Obj(cls=langchain_core.vectorstores.VectorStoreRetriever, id=139649925979968, init_bindings=None), name='get_relevant_documents')), RecordAppCallMethod(path=Lens().app.first.steps.context.first, method=Method(obj=Obj(cls=langchain_core.vectorstores.VectorStoreRetriever, id=139649925979968, init_bindings=None), name='_get_relevant_documents'))], args={'query': 'What is Task Decomposition?', 'run_manager': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManagerForRetrieverRun', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 139649925438480, 'init_bindings': None}}}, rets=[{'page_content': 'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.', 'metadata': {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, 'type': 'Document'}, {'page_content': 'Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.', 'metadata': {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, 'type': 'Document'}, {'page_content': 'Resources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.', 'metadata': {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, 'type': 'Document'}, {'page_content': \"(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\", 'metadata': {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, 'type': 'Document'}], error=None, perf=Perf(start_time=datetime.datetime(2024, 2, 23, 9, 32, 13, 475731), end_time=datetime.datetime(2024, 2, 23, 9, 32, 14, 6003)), pid=60822, tid=61909), RecordAppCall(stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=139650007898208, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableParallel, id=139649997860336, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps.context, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=139650007898208, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps.context.first, method=Method(obj=Obj(cls=langchain_core.vectorstores.VectorStoreRetriever, id=139649925979968, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps.context.first, method=Method(obj=Obj(cls=langchain_core.vectorstores.VectorStoreRetriever, id=139649925979968, init_bindings=None), name='get_relevant_documents'))], args={'query': 'What is Task Decomposition?', 'callbacks': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManager', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 139649926565520, 'init_bindings': None}}, 'tags': [], 'metadata': {}, 'run_name': None}, rets=[{'page_content': 'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.', 'metadata': {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, 'type': 'Document'}, {'page_content': 'Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.', 'metadata': {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, 'type': 'Document'}, {'page_content': 'Resources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.', 'metadata': {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, 'type': 'Document'}, {'page_content': \"(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\", 'metadata': {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, 'type': 'Document'}], error=None, perf=Perf(start_time=datetime.datetime(2024, 2, 23, 9, 32, 13, 432799), end_time=datetime.datetime(2024, 2, 23, 9, 32, 14, 7702)), pid=60822, tid=61908), RecordAppCall(stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=139650007898208, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableParallel, id=139649997860336, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps.context, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=139650007898208, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps.context.first, method=Method(obj=Obj(cls=langchain_core.vectorstores.VectorStoreRetriever, id=139649925979968, init_bindings=None), name='invoke'))], args={'input': 'What is Task Decomposition?', 'config': {'tags': [], 'metadata': {}, 'callbacks': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManager', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 139649926565520, 'init_bindings': None}}, 'recursion_limit': 25, 'configurable': {}}}, rets=[{'page_content': 'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.', 'metadata': {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, 'type': 'Document'}, {'page_content': 'Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.', 'metadata': {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, 'type': 'Document'}, {'page_content': 'Resources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.', 'metadata': {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, 'type': 'Document'}, {'page_content': \"(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\", 'metadata': {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, 'type': 'Document'}], error=None, perf=Perf(start_time=datetime.datetime(2024, 2, 23, 9, 32, 13, 368481), end_time=datetime.datetime(2024, 2, 23, 9, 32, 14, 9037)), pid=60822, tid=61906), RecordAppCall(stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=139650007898208, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableParallel, id=139649997860336, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first.steps.context, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=139650007898208, init_bindings=None), name='invoke'))], args={'input': 'What is Task Decomposition?', 'config': {'tags': [], 'metadata': {}, 'callbacks': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManager', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 139649925397328, 'init_bindings': None}}, 'recursion_limit': 25, 'configurable': {}}}, rets='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\n\\nResources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\\n\\n(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user\\'s request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.', error=None, perf=Perf(start_time=datetime.datetime(2024, 2, 23, 9, 32, 13, 293439), end_time=datetime.datetime(2024, 2, 23, 9, 32, 14, 11948)), pid=60822, tid=61904), RecordAppCall(stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=139650007898208, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.first, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableParallel, id=139649997860336, init_bindings=None), name='invoke'))], args={'input': 'What is Task Decomposition?', 'config': {'tags': [], 'metadata': {}, 'callbacks': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManager', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 139649926254992, 'init_bindings': None}}, 'recursion_limit': 25, 'configurable': {}}}, rets={'context': 'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\n\\nResources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\\n\\n(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user\\'s request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.', 'question': 'What is Task Decomposition?'}, error=None, perf=Perf(start_time=datetime.datetime(2024, 2, 23, 9, 32, 13, 240394), end_time=datetime.datetime(2024, 2, 23, 9, 32, 14, 13797)), pid=60822, tid=61902), RecordAppCall(stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=139650007898208, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.middle[0], method=Method(obj=Obj(cls=langchain_core.prompts.chat.ChatPromptTemplate, id=139649997101712, init_bindings=None), name='invoke'))], args={'input': {'context': 'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\n\\nResources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\\n\\n(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user\\'s request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.', 'question': 'What is Task Decomposition?'}, 'config': {'tags': [], 'metadata': {}, 'callbacks': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManager', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 139649922787088, 'init_bindings': None}}, 'recursion_limit': 25, 'configurable': {}}}, rets={'messages': [{'content': 'You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\\'t know the answer, just say that you don\\'t know. Use three sentences maximum and keep the answer concise.\\nQuestion: What is Task Decomposition? \\nContext: Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\n\\nResources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\\n\\n(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user\\'s request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path. \\nAnswer:', 'additional_kwargs': {}, 'type': 'human', 'name': None, 'example': False}]}, error=None, perf=Perf(start_time=datetime.datetime(2024, 2, 23, 9, 32, 14, 20915), end_time=datetime.datetime(2024, 2, 23, 9, 32, 14, 64899)), pid=60822, tid=61902), RecordAppCall(stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=139650007898208, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.middle[1], method=Method(obj=Obj(cls=langchain_community.chat_models.openai.ChatOpenAI, id=139649925977008, init_bindings=None), name='invoke'))], args={'input': {'messages': [{'content': 'You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\\'t know the answer, just say that you don\\'t know. Use three sentences maximum and keep the answer concise.\\nQuestion: What is Task Decomposition? \\nContext: Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\n\\nResources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\\n\\n(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user\\'s request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path. \\nAnswer:', 'additional_kwargs': {}, 'type': 'human', 'name': None, 'example': False}]}, 'config': {'tags': [], 'metadata': {}, 'callbacks': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManager', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 139649926480400, 'init_bindings': None}}, 'recursion_limit': 25, 'configurable': {}}}, rets={'content': 'Task Decomposition is a technique used to break down complex tasks into smaller and simpler steps. This approach helps agents to plan and execute tasks more efficiently by dividing them into manageable subgoals. Task decomposition can be achieved through various methods, such as using prompting techniques, task-specific instructions, or human inputs.', 'additional_kwargs': {}, 'type': 'ai', 'name': None, 'example': False}, error=None, perf=Perf(start_time=datetime.datetime(2024, 2, 23, 9, 32, 14, 69471), end_time=datetime.datetime(2024, 2, 23, 9, 32, 17, 521195)), pid=60822, tid=61902), RecordAppCall(stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=139650007898208, init_bindings=None), name='invoke')), RecordAppCallMethod(path=Lens().app.last, method=Method(obj=Obj(cls=langchain_core.output_parsers.string.StrOutputParser, id=139649997122256, init_bindings=None), name='invoke'))], args={'input': {'content': 'Task Decomposition is a technique used to break down complex tasks into smaller and simpler steps. This approach helps agents to plan and execute tasks more efficiently by dividing them into manageable subgoals. Task decomposition can be achieved through various methods, such as using prompting techniques, task-specific instructions, or human inputs.', 'additional_kwargs': {}, 'type': 'ai', 'name': None, 'example': False}, 'config': {'tags': [], 'metadata': {}, 'callbacks': {'__tru_non_serialized_object': {'cls': {'name': 'CallbackManager', 'module': {'package_name': 'langchain_core.callbacks', 'module_name': 'langchain_core.callbacks.manager'}, 'bases': None}, 'id': 139649854312016, 'init_bindings': None}}, 'recursion_limit': 25, 'configurable': {}}}, rets='Task Decomposition is a technique used to break down complex tasks into smaller and simpler steps. This approach helps agents to plan and execute tasks more efficiently by dividing them into manageable subgoals. Task decomposition can be achieved through various methods, such as using prompting techniques, task-specific instructions, or human inputs.', error=None, perf=Perf(start_time=datetime.datetime(2024, 2, 23, 9, 32, 17, 539973), end_time=datetime.datetime(2024, 2, 23, 9, 32, 17, 599490)), pid=60822, tid=61902), RecordAppCall(stack=[RecordAppCallMethod(path=Lens().app, method=Method(obj=Obj(cls=langchain_core.runnables.base.RunnableSequence, id=139650007898208, init_bindings=None), name='invoke'))], args={'input': 'What is Task Decomposition?'}, rets='Task Decomposition is a technique used to break down complex tasks into smaller and simpler steps. This approach helps agents to plan and execute tasks more efficiently by dividing them into manageable subgoals. Task decomposition can be achieved through various methods, such as using prompting techniques, task-specific instructions, or human inputs.', error=None, perf=Perf(start_time=datetime.datetime(2024, 2, 23, 9, 32, 13, 127592), end_time=datetime.datetime(2024, 2, 23, 9, 32, 17, 600175)), pid=60822, tid=60822)], feedback_and_future_results=[(Feedback(tru_class_info=trulens_eval.feedback.feedback.Feedback, implementation=Method(obj=Obj(cls=trulens_eval.feedback.provider.openai.OpenAI, id=139649923336864, init_bindings=Bindings(args=(), kwargs={'tru_class_info': {'name': 'OpenAI', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.openai'}, 'bases': [{'name': 'OpenAI', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.openai'}, 'bases': None}, {'name': 'LLMProvider', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.base'}, 'bases': None}, {'name': 'Provider', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.base'}, 'bases': None}, {'name': 'WithClassInfo', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.pyschema'}, 'bases': None}, {'name': 'SerialModel', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.serial'}, 'bases': None}, {'name': 'BaseModel', 'module': {'package_name': 'pydantic', 'module_name': 'pydantic.main'}, 'bases': None}, {'name': 'object', 'module': {'package_name': '', 'module_name': 'builtins'}, 'bases': None}]}, 'model_engine': 'gpt-3.5-turbo'})), name='relevance'), aggregator=Function(module=Module(package_name='numpy', module_name='numpy'), cls=None, name='mean'), feedback_definition_id='feedback_definition_hash_e533070933ec9bae448f039b5d0e81d1', selectors={'prompt': Lens().__record__.main_input, 'response': Lens().__record__.main_output}, supplied_name=None, higher_is_better=True, imp=<bound method LLMProvider.relevance of OpenAI(tru_class_info=trulens_eval.feedback.provider.openai.OpenAI, endpoint=OpenAIEndpoint(tru_class_info=trulens_eval.feedback.provider.endpoint.openai.OpenAIEndpoint, name='openai', rpm=60.0, retries=3, post_headers={}, pace=Pace(marks_per_second=1.0, seconds_per_period=60.0, seconds_per_period_timedelta=datetime.timedelta(seconds=60), mark_expirations=deque([datetime.datetime(2024, 2, 23, 9, 33, 18, 89426), datetime.datetime(2024, 2, 23, 9, 33, 18, 101030), datetime.datetime(2024, 2, 23, 9, 33, 18, 185015)]), max_marks=60, last_mark=datetime.datetime(2024, 2, 23, 9, 32, 18, 185015), lock=<unlocked _thread.lock object at 0x7f02cd060fc0>), global_callback=OpenAICallback(cost=Cost(n_requests=18, n_successful_requests=18, n_classes=0, n_tokens=8011, n_stream_chunks=0, n_prompt_tokens=7131, n_completion_tokens=880, cost=0.012393500000000002), langchain_handler=Tokens Used: 8011\n",
       "\tPrompt Tokens: 7131\n",
       "\tCompletion Tokens: 880\n",
       "Successful Requests: 18\n",
       "Total Cost (USD): $0.012393500000000002, chunks=[]), callback_class=<class 'trulens_eval.feedback.provider.endpoint.openai.OpenAICallback'>, callback_name='callback_openai', client=OpenAIClient(client=<openai.OpenAI object at 0x7f02ce75bad0>, client_cls=openai.OpenAI, client_kwargs={'organization': None, 'base_url': URL('https://api.openai.com/v1/'), 'timeout': Timeout(connect=5.0, read=600.0, write=600.0, pool=600.0), 'max_retries': 2, '_strict_response_validation': False})), model_engine='gpt-3.5-turbo')>, agg=<function mean at 0x7f030c1bc270>), <Future at 0x7f02c8159c10 state=running>), (Feedback(tru_class_info=trulens_eval.feedback.feedback.Feedback, implementation=Method(obj=Obj(cls=trulens_eval.feedback.provider.openai.OpenAI, id=139649923336864, init_bindings=Bindings(args=(), kwargs={'tru_class_info': {'name': 'OpenAI', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.openai'}, 'bases': [{'name': 'OpenAI', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.openai'}, 'bases': None}, {'name': 'LLMProvider', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.base'}, 'bases': None}, {'name': 'Provider', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.base'}, 'bases': None}, {'name': 'WithClassInfo', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.pyschema'}, 'bases': None}, {'name': 'SerialModel', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.serial'}, 'bases': None}, {'name': 'BaseModel', 'module': {'package_name': 'pydantic', 'module_name': 'pydantic.main'}, 'bases': None}, {'name': 'object', 'module': {'package_name': '', 'module_name': 'builtins'}, 'bases': None}]}, 'model_engine': 'gpt-3.5-turbo'})), name='qs_relevance'), aggregator=Function(module=Module(package_name='numpy', module_name='numpy'), cls=None, name='mean'), feedback_definition_id='feedback_definition_hash_885c6c33c89ac6364aa6952631d8be30', selectors={'question': Lens().__record__.main_input, 'statement': Lens().__record__.app.first.steps.context.first.get_relevant_documents.rets}, supplied_name=None, higher_is_better=True, imp=<bound method LLMProvider.qs_relevance of OpenAI(tru_class_info=trulens_eval.feedback.provider.openai.OpenAI, endpoint=OpenAIEndpoint(tru_class_info=trulens_eval.feedback.provider.endpoint.openai.OpenAIEndpoint, name='openai', rpm=60.0, retries=3, post_headers={}, pace=Pace(marks_per_second=1.0, seconds_per_period=60.0, seconds_per_period_timedelta=datetime.timedelta(seconds=60), mark_expirations=deque([datetime.datetime(2024, 2, 23, 9, 33, 18, 89426), datetime.datetime(2024, 2, 23, 9, 33, 18, 101030), datetime.datetime(2024, 2, 23, 9, 33, 18, 185015)]), max_marks=60, last_mark=datetime.datetime(2024, 2, 23, 9, 32, 18, 185015), lock=<unlocked _thread.lock object at 0x7f02cd060fc0>), global_callback=OpenAICallback(cost=Cost(n_requests=18, n_successful_requests=18, n_classes=0, n_tokens=8011, n_stream_chunks=0, n_prompt_tokens=7131, n_completion_tokens=880, cost=0.012393500000000002), langchain_handler=Tokens Used: 8011\n",
       "\tPrompt Tokens: 7131\n",
       "\tCompletion Tokens: 880\n",
       "Successful Requests: 18\n",
       "Total Cost (USD): $0.012393500000000002, chunks=[]), callback_class=<class 'trulens_eval.feedback.provider.endpoint.openai.OpenAICallback'>, callback_name='callback_openai', client=OpenAIClient(client=<openai.OpenAI object at 0x7f02ce75bad0>, client_cls=openai.OpenAI, client_kwargs={'organization': None, 'base_url': URL('https://api.openai.com/v1/'), 'timeout': Timeout(connect=5.0, read=600.0, write=600.0, pool=600.0), 'max_retries': 2, '_strict_response_validation': False})), model_engine='gpt-3.5-turbo')>, agg=<function mean at 0x7f030c1bc270>), <Future at 0x7f02c3ffb610 state=finished returned FeedbackResult>), (Feedback(tru_class_info=trulens_eval.feedback.feedback.Feedback, implementation=Method(obj=Obj(cls=trulens_eval.feedback.groundedness.Groundedness, id=139649922762384, init_bindings=Bindings(args=(), kwargs={'tru_class_info': {'name': 'Groundedness', 'module': {'package_name': 'trulens_eval.feedback', 'module_name': 'trulens_eval.feedback.groundedness'}, 'bases': [{'name': 'Groundedness', 'module': {'package_name': 'trulens_eval.feedback', 'module_name': 'trulens_eval.feedback.groundedness'}, 'bases': None}, {'name': 'WithClassInfo', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.pyschema'}, 'bases': None}, {'name': 'SerialModel', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.serial'}, 'bases': None}, {'name': 'BaseModel', 'module': {'package_name': 'pydantic', 'module_name': 'pydantic.main'}, 'bases': None}, {'name': 'object', 'module': {'package_name': '', 'module_name': 'builtins'}, 'bases': None}]}, 'groundedness_provider': {'tru_class_info': {'name': 'OpenAI', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.openai'}, 'bases': [{'name': 'OpenAI', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.openai'}, 'bases': None}, {'name': 'LLMProvider', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.base'}, 'bases': None}, {'name': 'Provider', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.base'}, 'bases': None}, {'name': 'WithClassInfo', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.pyschema'}, 'bases': None}, {'name': 'SerialModel', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.serial'}, 'bases': None}, {'name': 'BaseModel', 'module': {'package_name': 'pydantic', 'module_name': 'pydantic.main'}, 'bases': None}, {'name': 'object', 'module': {'package_name': '', 'module_name': 'builtins'}, 'bases': None}]}, 'model_engine': 'gpt-3.5-turbo'}})), name='groundedness_measure_with_cot_reasons'), aggregator=Method(obj=Obj(cls=trulens_eval.feedback.groundedness.Groundedness, id=139649922762384, init_bindings=Bindings(args=(), kwargs={'tru_class_info': {'name': 'Groundedness', 'module': {'package_name': 'trulens_eval.feedback', 'module_name': 'trulens_eval.feedback.groundedness'}, 'bases': [{'name': 'Groundedness', 'module': {'package_name': 'trulens_eval.feedback', 'module_name': 'trulens_eval.feedback.groundedness'}, 'bases': None}, {'name': 'WithClassInfo', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.pyschema'}, 'bases': None}, {'name': 'SerialModel', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.serial'}, 'bases': None}, {'name': 'BaseModel', 'module': {'package_name': 'pydantic', 'module_name': 'pydantic.main'}, 'bases': None}, {'name': 'object', 'module': {'package_name': '', 'module_name': 'builtins'}, 'bases': None}]}, 'groundedness_provider': {'tru_class_info': {'name': 'OpenAI', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.openai'}, 'bases': [{'name': 'OpenAI', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.openai'}, 'bases': None}, {'name': 'LLMProvider', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.base'}, 'bases': None}, {'name': 'Provider', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.base'}, 'bases': None}, {'name': 'WithClassInfo', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.pyschema'}, 'bases': None}, {'name': 'SerialModel', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.serial'}, 'bases': None}, {'name': 'BaseModel', 'module': {'package_name': 'pydantic', 'module_name': 'pydantic.main'}, 'bases': None}, {'name': 'object', 'module': {'package_name': '', 'module_name': 'builtins'}, 'bases': None}]}, 'model_engine': 'gpt-3.5-turbo'}})), name='grounded_statements_aggregator'), feedback_definition_id='feedback_definition_hash_2e4715a7ce5fee63a5fd6c0034648e3b', selectors={'source': Lens().__record__.app.first.steps.context.first.get_relevant_documents.rets.collect(), 'statement': Lens().__record__.main_output}, supplied_name=None, higher_is_better=True, imp=<bound method Groundedness.groundedness_measure_with_cot_reasons of Groundedness(tru_class_info=trulens_eval.feedback.groundedness.Groundedness, groundedness_provider=OpenAI(tru_class_info=trulens_eval.feedback.provider.openai.OpenAI, endpoint=OpenAIEndpoint(tru_class_info=trulens_eval.feedback.provider.endpoint.openai.OpenAIEndpoint, name='openai', rpm=60.0, retries=3, post_headers={}, pace=Pace(marks_per_second=1.0, seconds_per_period=60.0, seconds_per_period_timedelta=datetime.timedelta(seconds=60), mark_expirations=deque([datetime.datetime(2024, 2, 23, 9, 33, 18, 89426), datetime.datetime(2024, 2, 23, 9, 33, 18, 101030), datetime.datetime(2024, 2, 23, 9, 33, 18, 185015)]), max_marks=60, last_mark=datetime.datetime(2024, 2, 23, 9, 32, 18, 185015), lock=<unlocked _thread.lock object at 0x7f02cd060fc0>), global_callback=OpenAICallback(cost=Cost(n_requests=18, n_successful_requests=18, n_classes=0, n_tokens=8011, n_stream_chunks=0, n_prompt_tokens=7131, n_completion_tokens=880, cost=0.012393500000000002), langchain_handler=Tokens Used: 8011\n",
       "\tPrompt Tokens: 7131\n",
       "\tCompletion Tokens: 880\n",
       "Successful Requests: 18\n",
       "Total Cost (USD): $0.012393500000000002, chunks=[]), callback_class=<class 'trulens_eval.feedback.provider.endpoint.openai.OpenAICallback'>, callback_name='callback_openai', client=OpenAIClient(client=<openai.OpenAI object at 0x7f02ce75bad0>, client_cls=openai.OpenAI, client_kwargs={'organization': None, 'base_url': URL('https://api.openai.com/v1/'), 'timeout': Timeout(connect=5.0, read=600.0, write=600.0, pool=600.0), 'max_retries': 2, '_strict_response_validation': False})), model_engine='gpt-3.5-turbo'))>, agg=<bound method Groundedness.grounded_statements_aggregator of Groundedness(tru_class_info=trulens_eval.feedback.groundedness.Groundedness, groundedness_provider=OpenAI(tru_class_info=trulens_eval.feedback.provider.openai.OpenAI, endpoint=OpenAIEndpoint(tru_class_info=trulens_eval.feedback.provider.endpoint.openai.OpenAIEndpoint, name='openai', rpm=60.0, retries=3, post_headers={}, pace=Pace(marks_per_second=1.0, seconds_per_period=60.0, seconds_per_period_timedelta=datetime.timedelta(seconds=60), mark_expirations=deque([datetime.datetime(2024, 2, 23, 9, 33, 18, 89426), datetime.datetime(2024, 2, 23, 9, 33, 18, 101030), datetime.datetime(2024, 2, 23, 9, 33, 18, 185015)]), max_marks=60, last_mark=datetime.datetime(2024, 2, 23, 9, 32, 18, 185015), lock=<unlocked _thread.lock object at 0x7f02cd060fc0>), global_callback=OpenAICallback(cost=Cost(n_requests=18, n_successful_requests=18, n_classes=0, n_tokens=8011, n_stream_chunks=0, n_prompt_tokens=7131, n_completion_tokens=880, cost=0.012393500000000002), langchain_handler=Tokens Used: 8011\n",
       "\tPrompt Tokens: 7131\n",
       "\tCompletion Tokens: 880\n",
       "Successful Requests: 18\n",
       "Total Cost (USD): $0.012393500000000002, chunks=[]), callback_class=<class 'trulens_eval.feedback.provider.endpoint.openai.OpenAICallback'>, callback_name='callback_openai', client=OpenAIClient(client=<openai.OpenAI object at 0x7f02ce75bad0>, client_cls=openai.OpenAI, client_kwargs={'organization': None, 'base_url': URL('https://api.openai.com/v1/'), 'timeout': Timeout(connect=5.0, read=600.0, write=600.0, pool=600.0), 'max_retries': 2, '_strict_response_validation': False})), model_engine='gpt-3.5-turbo'))>), <Future at 0x7f02c833f390 state=finished returned FeedbackResult>)], feedback_results=[<Future at 0x7f02c8159c10 state=running>, <Future at 0x7f02c3ffb610 state=finished returned FeedbackResult>, <Future at 0x7f02c833f390 state=finished returned FeedbackResult>])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The record of the app invocation can be retrieved from the `recording`:\n",
    "\n",
    "rec = recording.get() # use .get if only one record\n",
    "# recs = recording.records # use .records if multiple\n",
    "\n",
    "display(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relevance 1.0\n",
      "qs_relevance 0.8\n",
      "groundedness_measure_with_cot_reasons 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# The results of the feedback functions can be rertireved from\n",
    "# `Record.feedback_results` or using the `wait_for_feedback_result` method. The\n",
    "# results if retrieved directly are `Future` instances (see\n",
    "# `concurrent.futures`). You can use `as_completed` to wait until they have\n",
    "# finished evaluating or use the utility method:\n",
    "\n",
    "for feedback, feedback_result in rec.wait_for_feedback_results().items():\n",
    "    print(feedback.name, feedback_result.result)\n",
    "\n",
    "# See more about wait_for_feedback_results:\n",
    "# help(rec.wait_for_feedback_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_json</th>\n",
       "      <th>type</th>\n",
       "      <th>record_id</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>tags</th>\n",
       "      <th>record_json</th>\n",
       "      <th>cost_json</th>\n",
       "      <th>perf_json</th>\n",
       "      <th>ts</th>\n",
       "      <th>qs_relevance</th>\n",
       "      <th>groundedness_measure_with_cot_reasons</th>\n",
       "      <th>relevance</th>\n",
       "      <th>qs_relevance_calls</th>\n",
       "      <th>groundedness_measure_with_cot_reasons_calls</th>\n",
       "      <th>relevance_calls</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chain1_ChatApplication</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruChain\", \"modul...</td>\n",
       "      <td>RunnableSequence(langchain_core.runnables.base)</td>\n",
       "      <td>record_hash_e38dfcf6d1e68b07b77f0328c09257f7</td>\n",
       "      <td>\"What is Task Decomposition?\"</td>\n",
       "      <td>\"Task Decomposition is a technique used to bre...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_e38dfcf6d1e68b07b77...</td>\n",
       "      <td>{\"n_requests\": 2, \"n_successful_requests\": 2, ...</td>\n",
       "      <td>{\"start_time\": \"2024-02-23T09:32:13.127592\", \"...</td>\n",
       "      <td>2024-02-23T09:32:17.600285</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'args': {'question': 'What is Task Decomposi...</td>\n",
       "      <td>[{'args': {'source': [[{'page_content': 'Fig. ...</td>\n",
       "      <td>[{'args': {'prompt': 'What is Task Decompositi...</td>\n",
       "      <td>4</td>\n",
       "      <td>650</td>\n",
       "      <td>0.000996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   app_id                                           app_json  \\\n",
       "0  Chain1_ChatApplication  {\"tru_class_info\": {\"name\": \"TruChain\", \"modul...   \n",
       "\n",
       "                                              type  \\\n",
       "0  RunnableSequence(langchain_core.runnables.base)   \n",
       "\n",
       "                                      record_id  \\\n",
       "0  record_hash_e38dfcf6d1e68b07b77f0328c09257f7   \n",
       "\n",
       "                           input  \\\n",
       "0  \"What is Task Decomposition?\"   \n",
       "\n",
       "                                              output tags  \\\n",
       "0  \"Task Decomposition is a technique used to bre...    -   \n",
       "\n",
       "                                         record_json  \\\n",
       "0  {\"record_id\": \"record_hash_e38dfcf6d1e68b07b77...   \n",
       "\n",
       "                                           cost_json  \\\n",
       "0  {\"n_requests\": 2, \"n_successful_requests\": 2, ...   \n",
       "\n",
       "                                           perf_json  \\\n",
       "0  {\"start_time\": \"2024-02-23T09:32:13.127592\", \"...   \n",
       "\n",
       "                           ts  qs_relevance  \\\n",
       "0  2024-02-23T09:32:17.600285           0.8   \n",
       "\n",
       "   groundedness_measure_with_cot_reasons  relevance  \\\n",
       "0                               0.666667        1.0   \n",
       "\n",
       "                                  qs_relevance_calls  \\\n",
       "0  [{'args': {'question': 'What is Task Decomposi...   \n",
       "\n",
       "         groundedness_measure_with_cot_reasons_calls  \\\n",
       "0  [{'args': {'source': [[{'page_content': 'Fig. ...   \n",
       "\n",
       "                                     relevance_calls  latency  total_tokens  \\\n",
       "0  [{'args': {'prompt': 'What is Task Decompositi...        4           650   \n",
       "\n",
       "   total_cost  \n",
       "0    0.000996  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[\"Chain1_ChatApplication\"])\n",
    "\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>groundedness_measure_with_cot_reasons</th>\n",
       "      <th>qs_relevance</th>\n",
       "      <th>relevance</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Chain1_ChatApplication</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        groundedness_measure_with_cot_reasons  qs_relevance  \\\n",
       "app_id                                                                        \n",
       "Chain1_ChatApplication                               0.666667           0.8   \n",
       "\n",
       "                        relevance  latency  total_cost  \n",
       "app_id                                                  \n",
       "Chain1_ChatApplication        1.0      4.0    0.000996  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[\"Chain1_ChatApplication\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Config file already exists. Skipping writing process.\n",
      "Credentials file already exists. Skipping writing process.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46962d4637074cf693c03cd1635a3b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Dashboard failed to start in time. Please inspect dashboard logs for additional information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtru\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_dashboard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# open a local streamlit app to explore\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# tru.stop_dashboard() # stop if needed\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/vivi/lib/python3.11/site-packages/trulens_eval/tru.py:1085\u001b[0m, in \u001b[0;36mTru.run_dashboard\u001b[0;34m(self, port, address, force, _dev)\u001b[0m\n\u001b[1;32m   1083\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m started\u001b[38;5;241m.\u001b[39mwait(timeout\u001b[38;5;241m=\u001b[39mwait_period):\n\u001b[1;32m   1084\u001b[0m     Tru\u001b[38;5;241m.\u001b[39m_dashboard_proc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1086\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDashboard failed to start in time. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1087\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease inspect dashboard logs for additional information.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1088\u001b[0m     )\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m proc\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Dashboard failed to start in time. Please inspect dashboard logs for additional information."
     ]
    }
   ],
   "source": [
    "tru.run_dashboard() # open a local streamlit app to explore\n",
    "\n",
    "# tru.stop_dashboard() # stop if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vivi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
